{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 吴恩达机器学习笔记（二）\n",
    "\n",
    "\n",
    "由于最近忙着找工作，更新进程一度被中断，两周前已经学完的课程，现在才有时间进行总结。\n",
    "\n",
    "本部分主要对应 [Coursera](coursera.org) 吴恩达机器学习的4~6周，神经网络部分。\n",
    "\n",
    "部分内容参考 [一文弄懂神经网络中的反向传播法——BackPropagation](https://www.cnblogs.com/charlotte77/p/5629865.html)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、神经网络\n",
    "\n",
    "动机：我们已经有线性回归、多项式回归和逻辑回归了，为什么还要研究神经网络？\n",
    "\n",
    "神经网络算法可以解决复杂的非线性问题。\n",
    "\n",
    "复杂的机器学习问题，涉及的项往往多于两项，这时候用逻辑回归或多项式回归，往往会有过拟合的问题，另外运算量也过大。\n",
    "\n",
    "神经网络是一种很古老的算法，他最初产生的目的是制造能模拟大脑的机器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、神经网络的结构\n",
    "\n",
    "神经网络的结构如下，分为输入层、隐含层和输出层。\n",
    "\n",
    "![神经网络结构](神经网络结构.png)\n",
    "\n",
    "其中，$x_0$, $a_0$ 为偏置，常设为1。\n",
    "\n",
    "对于多分类的情况，神经网络结构如下：\n",
    "![神经网络多分类结构](神经网络多分类结构.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、一个神经网络的完整传播过程\n",
    "\n",
    "以如下结构的神经网络为例，\n",
    "\n",
    "<img style=\"float: center;\" src=\"神经网络反向传播.jpg\" width=\"50%\">\n",
    "\n",
    "\n",
    "这个网络的输入为 X1、X2，X0=1 为输入层偏置，输出为h1、h2，隐含层为 a1、a2，a0=1 为隐含层偏置，激活函数为sigmoid函数。\n",
    "\n",
    "首先，对这个网络赋初值，\n",
    "\n",
    "输入数据：\n",
    "\n",
    "$$ x=[x_0, x_1, x_2]^T=[1, 0.05, 0.1]^T $$\n",
    "\n",
    "输出数据：\n",
    "\n",
    "$$ y=[y_1, y_2]^T=[0.01, 0.99]^T $$\n",
    "\n",
    "初始权值：\n",
    "\n",
    "$$ \\theta^{(1)} = \\left(\n",
    "  \\begin{array}{ccc}\n",
    "    \\theta_{01}^{(1)} & \\theta_{02}^{(1)}\\\\ \n",
    "    \\theta_{11}^{(1)} & \\theta_{12}^{(1)}\\\\  \n",
    "    \\theta_{21}^{(1)} & \\theta_{22}^{(1)}\\\\ \n",
    "  \\end{array}\n",
    "\\right) = \\left(\n",
    "  \\begin{array}{ccc}\n",
    "    0.35 & 0.35\\\\\n",
    "    0.15 & 0.25\\\\  \n",
    "    0.2 & 0.3\\\\ \n",
    "  \\end{array}\n",
    "\\right) $$\n",
    "\n",
    "$$ \\theta^{(2)} = \\left(\n",
    "  \\begin{array}{ccc}\n",
    "    \\theta_{01}^{(2)} & \\theta_{02}^{(2)}\\\\ \n",
    "    \\theta_{11}^{(2)} & \\theta_{12}^{(2)}\\\\  \n",
    "    \\theta_{21}^{(2)} & \\theta_{22}^{(2)}\\\\ \n",
    "  \\end{array}\n",
    "\\right) = \\left(\n",
    "  \\begin{array}{ccc}\n",
    "   0.6 & 0.6\\\\\n",
    "    0.4 & 0.5\\\\  \n",
    "    0.45 & 0.55\\\\ \n",
    "  \\end{array}\n",
    "\\right) $$\n",
    "\n",
    "\n",
    "### 3.1 前向传播\n",
    "\n",
    "(1) 输入层 --> 隐含层\n",
    "\n",
    "$$z_1^{(1)} = x_0 * \\theta_{01}^{(1)} + x_1 * \\theta_{11}^{(1)} + x_2 * \\theta_{21}^{(1)}=0.35*1+0.15*0.05+0.2*0.1=0.3775$$\n",
    "$$z_2^{(1)} = x_0 * \\theta_{02}^{(1)} + x_1 * \\theta_{12}^{(1)} + x_2 * \\theta_{22}^{(1)}=0.35*1+0.05*0.25+0.3*0.1=0.3925$$\n",
    "\n",
    "$$a_1 = g(z_1^{(1)})=0.59327$$\n",
    "$$a_2 = g(z_2^{(1)})=0.59688$$\n",
    "\n",
    "其中，$g(x) = sigmoid(x)=1/(1+\\exp(-x))$.\n",
    "\n",
    "(2) 隐含层 --> 输出层\n",
    "\n",
    "$$z_1^{(2)} = a_0 * \\theta_{01}^{(2)} + a_1 * \\theta_{11}^{(2)} + a_2 * \\theta_{21}^{(2)}$$\n",
    "$$z_2^{(2)} = a_0 * \\theta_{02}^{(2)} + a_1 * \\theta_{12}^{(2)} + a_2 * \\theta_{22}^{(2)}$$\n",
    "\n",
    "$$h_1 = g(z_1^{(2)})=0.75137$$\n",
    "$$h_2 = g(z_2^{(2)})=0.77293$$\n",
    "\n",
    "将以上**前向传播**的过程写成矩阵形式：\n",
    "\n",
    "$$(a_1, a_2)^T = g(\\theta^{(1)T}x)$$\n",
    "$$ a = (a_0, a_1, a_2)^T$$\n",
    "$$(h_1, h_2)^T = g(\\theta^{(2)T}a)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 反向传播\n",
    "\n",
    "(1) 计算总误差\n",
    "\n",
    "定义代价函数，\n",
    "\n",
    "$$\\begin{eqnarray*}\n",
    "J(\\theta) &=& -\\frac{1}{m}[\\sum_{i=1}^m\\sum_{k=1}^{K}( y_k^{(i)}\\log(h_k^{(i)})+(1-y_k^{(i)})\\log(1-h_k^{(i)})]+\\frac{\\lambda}{2m}\\sum_{l=1}^{L-1}\\sum_{i=1}^{s_l}\\sum_{j=1}^{s_{l+1}}(\\theta_{ji}^{(l)})^2\\\\ \n",
    "&=& -\\frac{1}{m}\\sum_{i=1}^{m}[y^T\\log(h)+(1-y)^T\\log(1-h))]+\\frac{\\lambda}{2m}\\sum_{l=1}^{L-1}\\sum_{i=1}^{s_l}\\sum_{j=1}^{s_{l+1}}(\\theta_{ji}^{(l)})^2\n",
    "\\end{eqnarray*}$$\n",
    "\n",
    "其中，$L$为总层数，$s_l$第$l$层的节点数量，$m$为样本数，$k$为输出节点数。\n",
    "\n",
    "在本例中，$L=2$，$s_1=2$，$s_2=2$，$m=1$，\n",
    "\n",
    "$$J(\\theta)=-[y^T\\log(h)+(1-y)^T\\log(1-h))]=1.6505$$\n",
    "\n",
    "（2）输出层 --> 隐含层的权值更新\n",
    "\n",
    "以权值$\\theta_{11}^{(2)}$为例，如果我们想知道$\\theta_{11}^{(2)}$对整体误差产生了多少影响，可以用整体误差对$\\theta_{11}^{(2)}$求偏导得到：\n",
    "\n",
    "$$\\frac{\\partial J(\\theta)}{\\partial \\theta_{11}^{(2)}}=\\frac{\\partial J(\\theta)}{\\partial h_1}*\\frac{\\partial h_1}{\\partial z_1^{(2)}}*\\frac{\\partial z_1^{(2)}}{\\partial \\theta_{11}^{(2)}}$$\n",
    "\n",
    "下图直观的反映了误差是怎样反向传播的：\n",
    "<img style=\"float: center;\" src=\"反向传播细节.jpg\" width=\"25%\">\n",
    "\n",
    "现在分别计算每个式子的值：\n",
    "\n",
    "$$\\frac{\\partial J(\\theta)}{\\partial h_1}=h_1-y_1=0.7414$$\n",
    "\n",
    "$$\\frac{\\partial h_1}{\\partial z_1^{(2)}}=h_1*(1-h_1)=0.1868$$\n",
    "\n",
    "$$\\frac{\\partial z_1^{(2)}}{\\partial \\theta_{11}^{(2)}}=a_1=0.59327$$\n",
    "\n",
    "将3式相乘：\n",
    "\n",
    "$$\\frac{\\partial J(\\theta)}{\\partial \\theta_{11}^{(2)}}=0.08217$$\n",
    "\n",
    "\n",
    "这样我们就计算出对$\\theta_{11}^{(2)}$的偏导数。\n",
    "\n",
    "回过头再看看上面的公式，我们发现：\n",
    "$$\\frac{\\partial J(\\theta)}{\\partial \\theta_{11}^{(2)}}=(h_1-y_1)*h_1*(1-h_1)*a_1$$\n",
    "\n",
    "为了方便，用$\\delta_{h1},\\delta_{h2}$来表示输出层误差：\n",
    "\n",
    "$$\\delta_{h1}=\\frac{\\partial J(\\theta)}{\\partial z_1}=\\frac{\\partial J(\\theta)}{\\partial h_1}*\\frac{\\partial h_1}{\\partial z_1^{(2)}}=(h_1-y_1)*h_1*(1-h_1)$$\n",
    "$$\\delta_{h2}=\\frac{\\partial J(\\theta)}{\\partial z_2}=\\frac{\\partial J(\\theta)}{\\partial h_2}*\\frac{\\partial h_2}{\\partial z_2^{(2)}}=(h_2-y_2)*h_2*(1-h_2)$$\n",
    "\n",
    "因此，整体误差对$\\theta_{11}^{(2)}$的偏导可以写成：\n",
    "$$\\frac{\\partial J(\\theta)}{\\partial \\theta_{11}^{(2)}}=\\delta_{h1}*a_1$$\n",
    "\n",
    "最后更新$\\theta_{11}^{(2)}$的值：\n",
    "$$\\theta_{11}^{(2)+}=\\theta_{11}^{(2)}-\\eta * \\delta_{h1}*a_1=0.3589$$\n",
    "其中，$\\eta$为学习率，这里取0.5。\n",
    "\n",
    "同理，可以更新$\\theta_{12}^{(2)},\\theta_{21}^{(2)},\\theta_{22}^{(2)}$：\n",
    "\n",
    "$$\\theta_{12}^{(2)+}=\\theta_{12}^{(2)} - \\eta * \\delta_{h2}*a_1=0.5113,$$\n",
    "$$\\theta_{21}^{(2)+}=\\theta_{21}^{(2)} - \\eta * \\delta_{h1}*a_2=0.4087,$$\n",
    "$$\\theta_{22}^{(2)+}=\\theta_{22}^{(2)} - \\eta * \\delta_{h2}*a_2=0.5614.$$\n",
    "\n",
    "----------\n",
    "\n",
    "将以上过程写成矩阵形式：\n",
    "$$\\delta_{h}=\\frac{\\partial J(\\theta)}{\\partial z}=\\frac{\\partial J(\\theta)}{\\partial h}*\\frac{\\partial h}{\\partial z^{(2)}}=(h-y)*h*(1-h)$$\n",
    "(注，这里的`*`为numpy中的`*`，代表对应元素相乘，Matlab中应为`.*`。)\n",
    "\n",
    "由于不更新偏置的权值，这里忽略对$\\theta_{01}^{(2)}$和$\\theta_{02}^{(2)}$的偏导，\n",
    "$$\\frac{\\partial J(\\theta)}{\\partial \\theta^{(2)}}=\\left(\n",
    "\\begin{array}{cc}\n",
    "\\frac{\\partial J(\\theta)}{\\partial \\theta_{11}^{(2)}} & \\frac{\\partial J(\\theta)}{\\partial \\theta_{12}^{(2)}}\\\\\n",
    "\\frac{\\partial J(\\theta)}{\\partial \\theta_{21}^{(2)}} & \\frac{\\partial J(\\theta)}{\\partial \\theta_{22}^{(2)}}\n",
    "\\end{array}\\right)\n",
    "=\\left( \\begin{array}{cc}\n",
    "\\delta_{h1}*a_1 & \\delta_{h2}*a_1 \\\\\n",
    "\\delta_{h1}*a_2 & \\delta_{h2}*a_2\n",
    "\\end{array} \\right)\n",
    "=(a_1, a_2)^T \\cdot \\delta_h^T$$\n",
    "$$\\theta^{(2)+} = \\theta^{(2)}[1:] - \\eta \\frac{\\partial J(\\theta)}{\\partial \\theta^{(2)}}$$\n",
    "(注，这里用了numpy中的语法，表示更新$\\theta^{(2)}$第一行以后的所有行。)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（3）隐含层-->输入层权值更新\n",
    "\n",
    "采取以上类似的步骤，但值得注意的是，在计算总误差对$\\theta^{(2)}_{11}$的偏导时，是从$h_1->z_1^{(2)}->\\theta^{(2)}_{11}$，但是在隐含层-->输入层（或者隐含层-->隐含层）的权值更新时，是$a_1->z_1^{(1)}->\\theta^{(1)}_{11}$，而$a_1$会接受两个地方传来的误差，所以这两个地方都要计算。\n",
    "\n",
    "$$\\frac{\\partial J(\\theta)}{\\partial \\theta^{(1)}_{11}}=(\\frac{\\partial J(\\theta)}{\\partial h_1} * \\frac{\\partial h_1}{\\partial z_1^{(2)}} * \\frac{\\partial z_1^{(2)}}{\\partial a_1} + \\frac{\\partial J(\\theta)}{\\partial h_2} * \\frac{\\partial h_2}{\\partial z_2^{(2)}} * \\frac{\\partial z_2^{(2)}}{\\partial a_1}) * \\frac{\\partial a_1}{\\partial z_1^{(1)}} * \\frac{\\partial z^{(1)}_1}{\\partial \\theta^{(1)}_{11}}$$\n",
    "\n",
    "同样的用$\\delta_{a1},\\delta_{a2}$代表隐含层误差，\n",
    "$$\\begin{eqnarray*} \\delta_{a1} &=& (\\frac{\\partial J(\\theta)}{\\partial h_1} * \\frac{\\partial h_1}{\\partial z_1^{(2)}} * \\frac{\\partial z_1^{(2)}}{\\partial a_1} + \\frac{\\partial J(\\theta)}{\\partial h_2} * \\frac{\\partial h_2}{\\partial z_2^{(2)}} * \\frac{\\partial z_2^{(2)}}{\\partial a_1}) * \\frac{\\partial a_1}{\\partial z_1^{(1)}}\\\\\n",
    "&=& ((h_1-y_1)h_1(1-h_1)\\theta_{11}^{(2)}+(h_2-y_2)h_2\\theta^{(2)}_{12}) * a_1(1-a_1)\\\\\n",
    "&=& (\\delta_{h1}\\theta_{11}^{(2)}+\\delta_{h2}\\theta_{12}^{(2)})a_1(1-a_1)\\\\\n",
    "&=& 0.008771\n",
    "\\end{eqnarray*}$$\n",
    "\n",
    "$$\\delta_{a2} = (\\delta_{h1}\\theta_{21}^{(2)}+\\delta_{h2}\\theta_{22}^{(2)})a_2(1-a_2)=0.009954$$\n",
    "\n",
    "输入层与隐含层之间的权值更新，\n",
    "$$\\theta^{(1)+}_{11} = \\theta^{(1)}_{11} - \\eta \\cdot \\delta_{a1} \\cdot x_1=0.1498$$\n",
    "$$\\theta^{(1)+}_{12} = \\theta^{(1)}_{12} - \\eta \\cdot \\delta_{a2} \\cdot x_1=0.2498$$\n",
    "$$\\theta^{(1)+}_{21} = \\theta^{(1)}_{21} - \\eta \\cdot \\delta_{a1} \\cdot x_2=0.1996$$\n",
    "$$\\theta^{(1)+}_{22} = \\theta^{(1)}_{22} - \\eta \\cdot \\delta_{a2} \\cdot x_2=0.2995$$\n",
    "\n",
    "-----------\n",
    "\n",
    "将以上过程写成矩阵形式，\n",
    "$$\\begin{eqnarray*}\n",
    "\\delta_{a} &=& \\left(\n",
    "\\begin{array}{cc}\n",
    "\\theta^{(2)}_{11} & \\theta_{12}^{(2)}\\\\\n",
    "\\theta_{21}^{(2)} & \\theta_{22}^{(2)}\n",
    "\\end{array}\\right)\n",
    "\\left( \\begin{array}{c}\n",
    "\\delta_{h1}\\\\\n",
    "\\delta_{h2}\n",
    "\\end{array}\\right)\n",
    "*\\left( \\begin{array}{c}\n",
    "a_1\\\\\n",
    "a_2\n",
    "\\end{array}\\right)\n",
    "*\\left( \\begin{array}{c}\n",
    "1-a_1\\\\\n",
    "1-a_2\n",
    "\\end{array}\\right)\\\\\n",
    "&=&\\theta^{(2)}[1:] \\cdot \\delta_{h} * a[1:]*(1-a[1:])\n",
    "\\end{eqnarray*}$$\n",
    "(注，这里的`*`为numpy中的`*`，代表对应元素相乘，Matlab中应为`.*`。)\n",
    "$$\\theta^{(1)+} = \\theta^{(1)}[1:] - \\eta * \\delta_a^T * x[1:]$$\n",
    "\n",
    "<font color=Crimson>注意，计算出所有权值的更新值后再统一更新，</font>\n",
    "\n",
    "$$\\theta^{(1)}[1:] = \\theta^{(1)+}$$\n",
    "$$\\theta^{(2)}[1:] = \\theta^{(2)+}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4、Python实现\n",
    "\n",
    "下面将用Python对上述的例子实现，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "x = np.array([1,0.05,0.1]).reshape(-1,1) # 列向量\n",
    "y = np.array([0.01, 0.99]).reshape(-1,1) # 列向量\n",
    "theta1 = np.array([[0.35,0.15,0.2],[0.35,0.25,0.3]]).T\n",
    "theta2 = np.array([[0.6,0.4,0.45],[0.6,0.5,0.55]]).T\n",
    "\n",
    "# 前向传播\n",
    "# 输入层-->隐含层\n",
    "z1 = np.dot(theta1.T, x)\n",
    "a = sigmoid(z1)\n",
    "a1, a2 = a[0], a[1]\n",
    "a = np.insert(a, 0, values = 1, axis = 0) # 在a[0]处插入1\n",
    "# 隐含层--> 输出层\n",
    "z2 = np.dot(theta2.T, a)\n",
    "h = sigmoid(z2)\n",
    "h1, h2 = h[0], h[1]\n",
    "\n",
    "# 反向传播\n",
    "# 代价函数（总误差）\n",
    "J = -(np.dot(y.T, np.log(h))+np.dot((1-y).T, np.log(1-h)))\n",
    "eta = 0.5\n",
    "# 输出层-->隐含层\n",
    "delta_h = (h-y)*h*(1-h)\n",
    "theta2_tmp = theta2[1:] - eta * delta_h.T * a[1:]\n",
    "# 隐含层-->输入层\n",
    "delta_a = theta2[1:] @ delta_h * a[1:] * (1-a[1:]) #numpy中@表示矩阵乘法，等同于np.dot()，*为对应元素相乘\n",
    "theta1_tmp = theta1[1:] - eta * delta_a.T * x[1:]\n",
    "# 最后更新权值\n",
    "theta1[1:] = theta1_tmp\n",
    "theta2[1:] = theta2_tmp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
